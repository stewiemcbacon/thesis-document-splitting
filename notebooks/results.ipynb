{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_hf = pd.read_csv('sim_scores/c1_headerfooter.csv', index_col = 0)\n",
    "c2_hf = pd.read_csv('sim_scores/c2_headerfooter.csv', index_col = 0)\n",
    "c1_d2v = pd.read_csv('sim_scores/d2v_skip_c1.csv', index_col = 0)\n",
    "c2_d2v = pd.read_csv('sim_scores/d2v_skip_c2.csv', index_col = 0)\n",
    "c1_tfidf = pd.read_csv('sim_scores/tfidf_skip_c1.csv', index_col = 0)\n",
    "c2_tfidf = pd.read_csv('sim_scores/tfidf_skip_c2.csv', index_col = 0)\n",
    "c1 = pd.read_csv('dfs/c1.csv', index_col = 0)\n",
    "c2 = pd.read_csv('dfs/c2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = c1.merge(c1_hf.drop(columns=['label']), how='left', on=['file_name','page']).merge(c1_d2v.drop(columns=['text_y_cleaned','label']), how='left',on=['full_name','page']).merge(c1_tfidf.drop(columns=['text_y_cleaned','label']), how='left',on=['full_name','page'])\n",
    "c2 = c2.merge(c2_hf.drop(columns=['label']), how='left', on=['file_name','page']).merge(c2_d2v.drop(columns=['text_y_cleaned','label']), how='left',on=['full_name','page']).merge(c2_tfidf.drop(columns=['text_y_cleaned','label']), how='left',on=['full_name','page'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_format(y):\n",
    "    y[0] = 1\n",
    "    indices = [i for i, x in enumerate(y) if x == 1]+[len(y)-1]\n",
    "    result = []\n",
    "    for i in range(len(indices)):\n",
    "        if i != len(indices)-1:\n",
    "            result.append(indices[i+1] - indices[i])\n",
    "    result[-1]+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index(split):\n",
    "    '''Turns a doc length vector like [1,2,1,3,3,5] into a dict with pagenumbers as keys and the set of all \n",
    "    pagenumbers in the same document as value.\n",
    "    This thus is an index which gives for every page its cluster.'''\n",
    "    l= sum(split)\n",
    "    pages= list(np.arange(l))\n",
    "    out = defaultdict(set)\n",
    "    for block_length in split:\n",
    "        block= pages[:block_length]\n",
    "        pages= pages[block_length:]\n",
    "        for page in block:\n",
    "            out[page]= set(block)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bcubed(truth,pred):\n",
    "    assert sum(truth)==sum(pred)  # same amount of pages\n",
    "    truth,pred = make_index(truth), make_index(pred)\n",
    "    \n",
    "    df  ={i:{'size':len(truth[i]),'P':0,'R':0,'F1':0} for i in truth}\n",
    "    for i in truth:\n",
    "        df[i]['P']= len(truth[i] & pred[i])/len(pred[i]) \n",
    "        df[i]['R']= len(truth[i] & pred[i])/len(truth[i])\n",
    "        df[i]['F1']= (2*df[i]['P']*df[i]['R'])/(df[i]['P']+df[i]['R'])\n",
    "    df= pd.DataFrame.from_dict(df, orient='index')\n",
    "    df.index_name='PageNr'\n",
    "    return  df\n",
    "\n",
    "\n",
    "def MeanBcubed(truth,pred):\n",
    "    assert sum(truth)==sum(pred)  # same amount of pages\n",
    "    return Bcubed(truth,pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "_c1 = c1[~pd.isnull(c1['text_y_cleaned'])]\n",
    "_c2 = c2[~pd.isnull(c2['text_y_cleaned'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual features Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train C1, Predict C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size    69.707824\n",
       "P        0.448520\n",
       "R        0.827935\n",
       "F1       0.369598\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_features = ['font_diff3','crop_diff','header_diff','footer_diff']\n",
    "model = LogisticRegression()\n",
    "model.fit(_c1[vis_features], _c1['label'])\n",
    "\n",
    "X_test = _c2[vis_features]\n",
    "y_test = _c2['label']\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "MeanBcubed(vb_truth, vb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train C2, Predict C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size    34.403323\n",
       "P        0.369691\n",
       "R        0.942905\n",
       "F1       0.404325\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_features = ['font_diff3','crop_diff','header_diff','footer_diff']\n",
    "model = LogisticRegression()\n",
    "model.fit(_c2[vis_features], _c2['label'])\n",
    "\n",
    "X_test = _c1[vis_features]\n",
    "y_test = _c1['label']\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "MeanBcubed(vb_truth, vb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF + visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train C1, predict C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size    69.707824\n",
       "P        0.462274\n",
       "R        0.819096\n",
       "F1       0.379936\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_features = ['font_diff3','crop_diff','header_diff','footer_diff','tfidf_sim']\n",
    "model = LogisticRegression()\n",
    "model.fit(_c1[vis_features], _c1['label'])\n",
    "\n",
    "X_test = _c2[vis_features]\n",
    "y_test = _c2['label']\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "MeanBcubed(vb_truth, vb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train C2, Predict C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size    34.403323\n",
       "P        0.455809\n",
       "R        0.942125\n",
       "F1       0.490227\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_features = ['font_diff3','crop_diff','header_diff','footer_diff', 'tfidf_sim']\n",
    "model = LogisticRegression()\n",
    "model.fit(_c2[vis_features], _c2['label'])\n",
    "\n",
    "X_test = _c1[vis_features]\n",
    "y_test = _c1['label']\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "MeanBcubed(vb_truth, vb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D2V + Visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train C1, predict C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size    69.707824\n",
       "P        0.559806\n",
       "R        0.768265\n",
       "F1       0.446680\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_features = ['font_diff3','crop_diff','header_diff','footer_diff','d2v_sim']\n",
    "model = LogisticRegression()\n",
    "model.fit(_c1[vis_features], _c1['label'])\n",
    "\n",
    "X_test = _c2[vis_features]\n",
    "y_test = _c2['label']\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "MeanBcubed(vb_truth, vb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train C2, Predict C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size    34.403323\n",
       "P        0.471147\n",
       "R        0.905422\n",
       "F1       0.483325\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_features = ['font_diff3','crop_diff','header_diff','footer_diff', 'd2v_sim']\n",
    "model = LogisticRegression()\n",
    "model.fit(_c2[vis_features], _c2['label'])\n",
    "\n",
    "X_test = _c1[vis_features]\n",
    "y_test = _c1['label']\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "MeanBcubed(vb_truth, vb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_old = pd.read_csv('dfs/c1_old.csv',index_col = 0)\n",
    "c2_old = pd.read_csv('dfs/c2_old.csv',index_col = 0)\n",
    "c1_bert = pd.read_csv('sim_scores/bert_skip_c1.csv',index_col = 0)\n",
    "c2_bert = pd.read_csv('sim_scores/bert_skip_c2.csv',index_col = 0)\n",
    "\n",
    "v1 = pickle.load(open('pickles/c1_vectors.p','rb'))\n",
    "v2 = pickle.load(open('pickles/c2_vectors.p','rb'))\n",
    "\n",
    "v1_trunc = pickle.load(open('pickles/c1_vectors_trunc.p','rb'))\n",
    "v2_trunc = pickle.load(open('pickles/c2_vectors_trunc.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_old = c1_old.merge(c1_bert.drop(columns=['text_y_cleaned','label']), on = ['full_name','page'])\n",
    "c2_old = c2_old.merge(c2_bert.drop(columns=['text_y_cleaned','label']), on = ['full_name','page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf1 = MLPClassifier(\n",
    "    hidden_layer_sizes = (128,),\n",
    "    batch_size = 50,\n",
    "    solver = 'adam',\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# clf1.fit(v1, c1_old['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = MLPClassifier(\n",
    "    hidden_layer_sizes = (128,),\n",
    "    batch_size = 50,\n",
    "    solver = 'adam',\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# clf2.fit(v2, c2_old['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_old['bert_proba'] = clf1.predict_proba(v2)[:,1]\n",
    "c1_old['bert_proba'] = clf2.predict_proba(v1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_c1_old = c1_old[~pd.isnull(c1_old['text_y_cleaned'])]\n",
    "_c2_old = c2_old[~pd.isnull(c2_old['text_y_cleaned'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "# c1[['page','crop_diff','font_diff3','footer_diff','header_diff','label']][:200]\n",
    "# c1[c1['font_diff3'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on c1, predict c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    68.910383\n",
      "P        0.684255\n",
      "R        0.693042\n",
      "F1       0.537675\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train = v1\n",
    "y_train = c1_old['label']\n",
    "X_test = v2\n",
    "y_test = c2_old['label']\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes = (128,),\n",
    "    batch_size = 50,\n",
    "    solver = 'adam',\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = clf.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(clf.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual + Bert_similarity i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    68.910383\n",
      "P        0.434505\n",
      "R        0.833364\n",
      "F1       0.355291\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = ['font_diff3','crop_diff','bert_sim']\n",
    "\n",
    "X_train = c1_old[features]\n",
    "y_train = c1_old['label']\n",
    "X_test = c2_old[features]\n",
    "y_test = c2_old['label']\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual + Bert_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    68.910383\n",
      "P        0.593553\n",
      "R        0.724658\n",
      "F1       0.431767\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = ['font_diff3','crop_diff','bert_proba']\n",
    "\n",
    "X_train = c1_old[features]\n",
    "y_train = c1_old['label']\n",
    "X_test = c2_old[features]\n",
    "y_test = c2_old['label']\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on c2, predict c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    34.380975\n",
      "P        0.648183\n",
      "R        0.725552\n",
      "F1       0.537412\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# features = ['font_diff2','crop_diff','text_d2v_sim_score']\n",
    "X_train = v2\n",
    "y_train = c2_old['label']\n",
    "X_test = v1\n",
    "y_test = c1_old['label']\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes = (128,),\n",
    "    batch_size = 50,\n",
    "    solver = 'adam',\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = clf.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(clf.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual + Bert_similarity i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    34.380975\n",
      "P        0.150656\n",
      "R        0.962881\n",
      "F1       0.183027\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = ['font_diff3','crop_diff','bert_sim']\n",
    "\n",
    "X_train = c2_old[features]\n",
    "y_train = c2_old['label']\n",
    "X_test = c1_old[features]\n",
    "y_test = c1_old['label']\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = clf.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(clf.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual + Bert_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    34.380975\n",
      "P        0.350439\n",
      "R        0.963462\n",
      "F1       0.420291\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "features = ['font_diff3','crop_diff','bert_proba']\n",
    "\n",
    "X_train = c2_old[features]\n",
    "y_train = c2_old['label']\n",
    "X_test = c1_old[features]\n",
    "y_test = c1_old['label']\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = clf.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(clf.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - BERT + Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19101/19101 [00:03<00:00, 5043.83it/s]\n",
      "100%|██████████| 16537/16537 [00:03<00:00, 5085.18it/s]\n"
     ]
    }
   ],
   "source": [
    "v1_plus = [np.append(v1[i], [c1_old.iloc[i]['font_diff3'], c1_old.iloc[i]['crop_diff']]) for i in tqdm(range(len(v1)))]\n",
    "v2_plus = [np.append(v2[i], [c2_old.iloc[i]['font_diff3'], c2_old.iloc[i]['crop_diff']]) for i in tqdm(range(len(v2)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train C1, Predict C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    68.910383\n",
      "P        0.633823\n",
      "R        0.720345\n",
      "F1       0.498019\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# features = ['font_diff2','crop_diff','text_d2v_sim_score']\n",
    "X_train = v1_plus\n",
    "y_train = c1_old['label']\n",
    "X_test = v2_plus\n",
    "y_test = c2_old['label']\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes = (128,),\n",
    "    batch_size = 50,\n",
    "    solver = 'adam',\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = clf.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(clf.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train C2, Predict C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size    34.380975\n",
      "P        0.783197\n",
      "R        0.715920\n",
      "F1       0.631302\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# features = ['font_diff2','crop_diff','text_d2v_sim_score']\n",
    "X_train = v2_plus\n",
    "y_train = c2_old['label']\n",
    "X_test = v1_plus\n",
    "y_test = c1_old['label']\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes = (128,),\n",
    "    batch_size = 50,\n",
    "    solver = 'adam',\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "true = y_test\n",
    "preds = clf.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(clf.predict(X_test))\n",
    "print(MeanBcubed(vb_truth,vb_pred))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0ef08d8ed6cc4ea55e1d44bd248b5018e6b6290053252328e46dd8d04768404"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('thesis8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
