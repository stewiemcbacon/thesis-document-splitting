{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pd.read_csv('dfs/c1.csv',index_col = 0)\n",
    "c2 = pd.read_csv('dfs/c2.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob\n",
    "\n",
    "NGRAM = 2\n",
    "\n",
    "re_sent_ends_naive = re.compile(r'[.\\n]')\n",
    "re_stripper_alpha = re.compile('[^a-zA-Z]+')\n",
    "re_stripper_naive = re.compile('[^a-zA-Z\\.\\n]')\n",
    "\n",
    "splitter_naive = lambda x: re_sent_ends_naive.split(re_stripper_naive.sub(' ', x))\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/dutch.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuples_nosentences(txt, NGRAM):\n",
    "    \"\"\"Get tuples that ignores all punctuation (including sentences).\"\"\"\n",
    "    if not txt: return None\n",
    "    ng = ngrams(re_stripper_alpha.sub(' ', txt).split(), NGRAM)\n",
    "    return list(ng)\n",
    "\n",
    "def get_char_tuples(txt, n):\n",
    "    if not txt: return None\n",
    "    return [tuple(txt[i:i+n]) for i in range(len(txt)-n+1)]\n",
    "\n",
    "def get_tuples_manual_sentences(txt):\n",
    "    \"\"\"Naive get tuples that uses periods or newlines to denote sentences.\"\"\"\n",
    "    if not txt: return None\n",
    "    sentences = (x.split() for x in splitter_naive(txt) if x)\n",
    "    ng = (ngrams(x, NGRAM) for x in sentences if len(x) >= NGRAM)\n",
    "    return list(chain(*ng))\n",
    "\n",
    "def get_tuples_nltk_punkt_sentences(txt):\n",
    "    \"\"\"Get tuples that doesn't use textblob.\"\"\"\n",
    "    if not txt: return None\n",
    "    sentences = (re_stripper_alpha.split(x) for x in sent_detector.tokenize(txt) if x)\n",
    "    # Need to filter X because of empty 'words' from punctuation split\n",
    "    ng = (ngrams(filter(None, x), NGRAM) for x in sentences if len(x) >= NGRAM)\n",
    "    return list(chain(*ng))\n",
    "\n",
    "def get_tuples_textblob_sentences(txt):\n",
    "    \"\"\"New get_tuples that does use textblob.\"\"\"\n",
    "    if not txt: return None\n",
    "    tb = TextBlob(txt)\n",
    "    ng = (ngrams(x.words, NGRAM) for x in tb.sentences if len(x.words) > NGRAM)\n",
    "    return [item for sublist in ng for item in sublist]\n",
    "\n",
    "def jaccard_distance(a, b):\n",
    "    \"\"\"Calculate the jaccard distance between sets A and B\"\"\"\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    if len(a|b) == 0:\n",
    "        return 0.0\n",
    "    return 1.0 * len(a&b)/len(a|b)\n",
    "\n",
    "def cosine_similarity_ngrams(a, b):\n",
    "    vec1 = Counter(a)\n",
    "    vec2 = Counter(b)\n",
    "    \n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.011111111111111112   Cosine: 0.01934558081335342\n"
     ]
    }
   ],
   "source": [
    "NGRAM = 1\n",
    "\n",
    "a = get_tuples_nosentences(c1.iloc[36]['text_y_cleaned'],NGRAM)\n",
    "b = get_tuples_nosentences(c1.iloc[34]['text_y_cleaned'],NGRAM)\n",
    "print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(df, max_ngrams):\n",
    "    it = iter(range(1,len(df)))\n",
    "    diffs = defaultdict(list)\n",
    "    for n in range(max_ngrams):\n",
    "        diffs[str(n+1)+'_cos'].append(0)\n",
    "        diffs[str(n+1)+'_jac'].append(0)\n",
    "        diffs[str(n+1)+'_cos_char'].append(0)\n",
    "        diffs[str(n+1)+'_jac_char'].append(0)\n",
    "\n",
    "\n",
    "    for i in tqdm(it):\n",
    "        a = df.iloc[i]['text_y_cleaned']\n",
    "        b = df.iloc[i-1]['text_y_cleaned']\n",
    "\n",
    "        if pd.isnull(a):\n",
    "            j = i\n",
    "            skips = 0\n",
    "\n",
    "            while pd.isnull(df.iloc[j]['text_y_cleaned']):\n",
    "                for n in range(max_ngrams):\n",
    "                    diffs[str(n+1)+'_cos'].append(0)\n",
    "                    diffs[str(n+1)+'_jac'].append(0)\n",
    "                    diffs[str(n+1)+'_cos_char'].append(0)\n",
    "                    diffs[str(n+1)+'_jac_char'].append(0)\n",
    "                j+=1\n",
    "                skips+=1\n",
    "            \n",
    "            a = df.iloc[j]['text_y_cleaned']\n",
    "\n",
    "            for n in range(max_ngrams):\n",
    "                NGRAM = n+1\n",
    "                # Word ngrams\n",
    "                a_tup = get_tuples_nosentences(a, NGRAM)\n",
    "                b_tup = get_tuples_nosentences(b, NGRAM)\n",
    "                diffs[str(n+1)+'_cos'].append(cosine_similarity_ngrams(a_tup,b_tup))\n",
    "                diffs[str(n+1)+'_jac'].append(jaccard_distance(a_tup,b_tup))\n",
    "\n",
    "                # Char ngrams\n",
    "                a_tup = get_char_tuples(a, NGRAM)\n",
    "                b_tup = get_char_tuples(b, NGRAM)\n",
    "                diffs[str(n+1)+'_cos_char'].append(cosine_similarity_ngrams(a_tup,b_tup))\n",
    "                diffs[str(n+1)+'_jac_char'].append(jaccard_distance(a_tup,b_tup))\n",
    "\n",
    "\n",
    "            for _ in range(skips):\n",
    "                i = next(it)\n",
    "\n",
    "        else:\n",
    "            for n in range(max_ngrams):\n",
    "                NGRAM = n+1\n",
    "                # Word ngrams\n",
    "                a_tup = get_tuples_nosentences(a, NGRAM)\n",
    "                b_tup = get_tuples_nosentences(b, NGRAM)\n",
    "                diffs[str(n+1)+'_cos'].append(cosine_similarity_ngrams(a_tup,b_tup))\n",
    "                diffs[str(n+1)+'_jac'].append(jaccard_distance(a_tup,b_tup))\n",
    "\n",
    "                # Char ngrams\n",
    "                a_tup = get_char_tuples(a, NGRAM)\n",
    "                b_tup = get_char_tuples(b, NGRAM)\n",
    "                diffs[str(n+1)+'_cos_char'].append(cosine_similarity_ngrams(a_tup,b_tup))\n",
    "                diffs[str(n+1)+'_jac_char'].append(jaccard_distance(a_tup,b_tup))\n",
    "\n",
    "\n",
    "    return pd.DataFrame(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18116it [01:03, 283.23it/s]\n"
     ]
    }
   ],
   "source": [
    "d1 = c1.join(compare(c1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['full_name', 'file_name', 'page', 'cropbox_x', 'cropbox_y', 'text_x',\n",
       "       'text_y', 'text_y_cleaned', 'header', 'footer', 'fonts',\n",
       "       'preprocessed_text', 'isImage', 'isLastPage', 'crop_diff', 'font_diff3',\n",
       "       'label', '1_cos', '1_jac', '1_cos_char', '1_jac_char', '2_cos', '2_jac',\n",
       "       '2_cos_char', '2_jac_char', '3_cos', '3_jac', '3_cos_char',\n",
       "       '3_jac_char'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "d1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "\n",
    "\n",
    "def compare2(df, max_ngrams, n):\n",
    "    shifts = dict()\n",
    "    diffs = defaultdict(list)\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(n):\n",
    "        shifts[(i+1)*-1] = c1.shift(i+1)\n",
    "        shifts[(-i-1)*-1] = c1.shift(-i-1)\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        a = df.iloc[i]['text_y_cleaned']\n",
    "\n",
    "        for j in shifts.keys():\n",
    "            b = shifts[j].iloc[i]['text_y_cleaned']\n",
    "\n",
    "            for k in range(max_ngrams):\n",
    "                if pd.isnull(a) or pd.isnull(b):\n",
    "                    diffs[str(k+1)+'_cos_'+str(j)].append(0)\n",
    "                    diffs[str(k+1)+'_jac_'+str(j)].append(0)\n",
    "                    diffs[str(k+1)+'_cos_char_'+str(j)].append(0)\n",
    "                    diffs[str(k+1)+'_jac_char_'+str(j)].append(0)\n",
    "                    continue\n",
    "\n",
    "                # Word ngrams\n",
    "                a_tup = get_tuples_nosentences(a,k+1)\n",
    "                b_tup = get_tuples_nosentences(b,k+1)\n",
    "                diffs[str(k+1)+'_cos_'+str(j)].append(cosine_similarity_ngrams(a_tup,b_tup))\n",
    "                diffs[str(k+1)+'_jac_'+str(j)].append(jaccard_distance(a_tup,b_tup))\n",
    "\n",
    "                # Char ngrams\n",
    "                a_tup = get_char_tuples(a,k+1)\n",
    "                b_tup = get_char_tuples(b,k+1)\n",
    "                diffs[str(k+1)+'_cos_char_'+str(j)].append(cosine_similarity_ngrams(a_tup,b_tup))\n",
    "                diffs[str(k+1)+'_jac_char_'+str(j)].append(jaccard_distance(a_tup,b_tup))\n",
    "\n",
    "    return pd.DataFrame(diffs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19102/19102 [06:15<00:00, 50.84it/s] \n",
      "100%|██████████| 16537/16537 [05:30<00:00, 50.01it/s] \n"
     ]
    }
   ],
   "source": [
    "c1_sims = c1.join(compare2(c1, 3, 3))\n",
    "c2_sims = c2.join(compare2(c2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_format(y):\n",
    "    y[0] = 1\n",
    "    indices = [i for i, x in enumerate(y) if x == 1]+[len(y)-1]\n",
    "    result = []\n",
    "    for i in range(len(indices)):\n",
    "        if i != len(indices)-1:\n",
    "            result.append(indices[i+1] - indices[i])\n",
    "    result[-1]+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index(split):\n",
    "    '''Turns a doc length vector like [1,2,1,3,3,5] into a dict with pagenumbers as keys and the set of all \n",
    "    pagenumbers in the same document as value.\n",
    "    This thus is an index which gives for every page its cluster.'''\n",
    "    l= sum(split)\n",
    "    pages= list(np.arange(l))\n",
    "    out = defaultdict(set)\n",
    "    for block_length in split:\n",
    "        block= pages[:block_length]\n",
    "        pages= pages[block_length:]\n",
    "        for page in block:\n",
    "            out[page]= set(block)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bcubed(truth,pred):\n",
    "    assert sum(truth)==sum(pred)  # same amount of pages\n",
    "    truth,pred = make_index(truth), make_index(pred)\n",
    "    \n",
    "    df  ={i:{'size':len(truth[i]),'P':0,'R':0,'F1':0} for i in truth}\n",
    "    for i in truth:\n",
    "        df[i]['P']= len(truth[i] & pred[i])/len(pred[i]) \n",
    "        df[i]['R']= len(truth[i] & pred[i])/len(truth[i])\n",
    "        df[i]['F1']= (2*df[i]['P']*df[i]['R'])/(df[i]['P']+df[i]['R'])\n",
    "    df= pd.DataFrame.from_dict(df, orient='index')\n",
    "    df.index_name='PageNr'\n",
    "    return  df\n",
    "\n",
    "\n",
    "def MeanBcubed(truth,pred):\n",
    "    assert sum(truth)==sum(pred)  # same amount of pages\n",
    "    return Bcubed(truth,pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>page</th>\n",
       "      <th>cropbox_x</th>\n",
       "      <th>cropbox_y</th>\n",
       "      <th>text_x</th>\n",
       "      <th>text_y</th>\n",
       "      <th>text_y_cleaned</th>\n",
       "      <th>header</th>\n",
       "      <th>footer</th>\n",
       "      <th>...</th>\n",
       "      <th>1_cos_char3</th>\n",
       "      <th>1_jac_char3</th>\n",
       "      <th>2_cos_3</th>\n",
       "      <th>2_jac_3</th>\n",
       "      <th>2_cos_char3</th>\n",
       "      <th>2_jac_char3</th>\n",
       "      <th>3_cos_3</th>\n",
       "      <th>3_jac_3</th>\n",
       "      <th>3_cos_char3</th>\n",
       "      <th>3_jac_char3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>868212__concatenated-001.txt</td>\n",
       "      <td>868212</td>\n",
       "      <td>1</td>\n",
       "      <td>419.528015</td>\n",
       "      <td>595.276001</td>\n",
       "      <td>Handreiking \\nVeilige Moskee\\n</td>\n",
       "      <td>\\n\\nHandreiking\\n\\nVeilige Moskee\\n\\n \\n</td>\n",
       "      <td>handreik veilig moskee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898450</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.164153</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.512104</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.081111</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.476742</td>\n",
       "      <td>0.032573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>868212__concatenated-002.txt</td>\n",
       "      <td>868212</td>\n",
       "      <td>2</td>\n",
       "      <td>419.528015</td>\n",
       "      <td>595.276001</td>\n",
       "      <td>1\\nHandreiking | Veilige Moskee\\nInhoudsopgave...</td>\n",
       "      <td>Handreiking | Veilige Moskee\\n\\nInhoudsopgave\\...</td>\n",
       "      <td>handreik veilig moskee inhoudsopgav inleid aar...</td>\n",
       "      <td>Handreiking | Veilige Moskee</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975678</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.042796</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.701130</td>\n",
       "      <td>0.497561</td>\n",
       "      <td>0.022283</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.400137</td>\n",
       "      <td>0.187359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>868212__concatenated-003.txt</td>\n",
       "      <td>868212</td>\n",
       "      <td>3</td>\n",
       "      <td>419.528015</td>\n",
       "      <td>595.276001</td>\n",
       "      <td>3\\nHandreiking | Veilige Moskee\\n1. Inleiding\\...</td>\n",
       "      <td>Handreiking | Veilige Moskee\\n\\n1. Inleiding\\n...</td>\n",
       "      <td>handreik veilig moskee inleid moskee gebedshui...</td>\n",
       "      <td>Handreiking | Veilige Moskee</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986773</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.038490</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.873152</td>\n",
       "      <td>0.602362</td>\n",
       "      <td>0.019631</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.650754</td>\n",
       "      <td>0.256065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868212__concatenated-004.txt</td>\n",
       "      <td>868212</td>\n",
       "      <td>4</td>\n",
       "      <td>419.528015</td>\n",
       "      <td>595.276001</td>\n",
       "      <td>4\\nHandreiking | Veilige Moskee\\nTips voor mos...</td>\n",
       "      <td>Handreiking | Veilige Moskee\\n\\nTips voor mosk...</td>\n",
       "      <td>handreik veilig moskee tip moskee gemeent poli...</td>\n",
       "      <td>Handreiking | Veilige Moskee</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983317</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.022635</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.879288</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.630186</td>\n",
       "      <td>0.325933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>868212__concatenated-005.txt</td>\n",
       "      <td>868212</td>\n",
       "      <td>5</td>\n",
       "      <td>419.528015</td>\n",
       "      <td>595.276001</td>\n",
       "      <td>5\\nHandreiking | Veilige Moskee\\nAanvullingen\\...</td>\n",
       "      <td>Handreiking | Veilige Moskee\\n\\nAanvullingen\\n...</td>\n",
       "      <td>handreik veilig moskee aanvull handreik defini...</td>\n",
       "      <td>Handreiking | Veilige Moskee</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982468</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.046524</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.760221</td>\n",
       "      <td>0.547325</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.480749</td>\n",
       "      <td>0.231579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>993914_files.zip__concatenated-204.txt</td>\n",
       "      <td>993914_files.zip</td>\n",
       "      <td>204</td>\n",
       "      <td>595.219971</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>6\\nT + 31 (0)\\n  \\n@amsterdam.nl \\n \\n</td>\n",
       "      <td>T + 32 N\\n\\n-®amsterdam.nl\\n\\n \\n</td>\n",
       "      <td>amsterdam nl</td>\n",
       "      <td>T + 31 (0)     @amsterdam.nl</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659141</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.006079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>993914__concatenated-1.txt</td>\n",
       "      <td>993914</td>\n",
       "      <td>1</td>\n",
       "      <td>595.320007</td>\n",
       "      <td>841.919983</td>\n",
       "      <td>Aantekeningen \\nZienswijzeverzoeken \\nBelanghe...</td>\n",
       "      <td>Aantekeningen\\nZienswijzeverzoeken\\n\\n \\n\\n \\n...</td>\n",
       "      <td>aanteken belanghebb partij document politie dr...</td>\n",
       "      <td>Aantekeningen  Zienswijzeverzoeken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667565</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356729</td>\n",
       "      <td>0.146233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>993914__concatenated-2.txt</td>\n",
       "      <td>993914</td>\n",
       "      <td>2</td>\n",
       "      <td>595.320007</td>\n",
       "      <td>841.919983</td>\n",
       "      <td>Geheimhouding politiegegevens \\n(artikel 7, tw...</td>\n",
       "      <td>\\n\\nGeheimhouding politiegegevens\\n(artikel 7...</td>\n",
       "      <td>geheimhoud politiegegeven artikel twed lid wpg...</td>\n",
       "      <td>Geheimhouding politiegegevens  (artikel 7, twe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100</th>\n",
       "      <td>993914__concatenated-3.txt</td>\n",
       "      <td>993914</td>\n",
       "      <td>3</td>\n",
       "      <td>595.320007</td>\n",
       "      <td>841.919983</td>\n",
       "      <td>55 \\nGemeente \\nE-mails over cijfermatige\\ndat...</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n ...</td>\n",
       "      <td>gemeent mail cijfermat gedeelt open art lid da...</td>\n",
       "      <td>55  Gemeente  E-mails over cijfermatige datage...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19101</th>\n",
       "      <td>993914__concatenated-4.txt</td>\n",
       "      <td>993914</td>\n",
       "      <td>4</td>\n",
       "      <td>595.320007</td>\n",
       "      <td>841.919983</td>\n",
       "      <td>179 \\nGemeente \\nVoorstel onderzoek \\nwapencon...</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n ...</td>\n",
       "      <td>gemeent voorstel onderzoek gedeelt open art li...</td>\n",
       "      <td>179  Gemeente  Voorstel onderzoek  wapencontro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19102 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    full_name         file_name  page  \\\n",
       "0                868212__concatenated-001.txt            868212     1   \n",
       "1                868212__concatenated-002.txt            868212     2   \n",
       "2                868212__concatenated-003.txt            868212     3   \n",
       "3                868212__concatenated-004.txt            868212     4   \n",
       "4                868212__concatenated-005.txt            868212     5   \n",
       "...                                       ...               ...   ...   \n",
       "19097  993914_files.zip__concatenated-204.txt  993914_files.zip   204   \n",
       "19098              993914__concatenated-1.txt            993914     1   \n",
       "19099              993914__concatenated-2.txt            993914     2   \n",
       "19100              993914__concatenated-3.txt            993914     3   \n",
       "19101              993914__concatenated-4.txt            993914     4   \n",
       "\n",
       "        cropbox_x   cropbox_y  \\\n",
       "0      419.528015  595.276001   \n",
       "1      419.528015  595.276001   \n",
       "2      419.528015  595.276001   \n",
       "3      419.528015  595.276001   \n",
       "4      419.528015  595.276001   \n",
       "...           ...         ...   \n",
       "19097  595.219971  842.000000   \n",
       "19098  595.320007  841.919983   \n",
       "19099  595.320007  841.919983   \n",
       "19100  595.320007  841.919983   \n",
       "19101  595.320007  841.919983   \n",
       "\n",
       "                                                  text_x  \\\n",
       "0                         Handreiking \\nVeilige Moskee\\n   \n",
       "1      1\\nHandreiking | Veilige Moskee\\nInhoudsopgave...   \n",
       "2      3\\nHandreiking | Veilige Moskee\\n1. Inleiding\\...   \n",
       "3      4\\nHandreiking | Veilige Moskee\\nTips voor mos...   \n",
       "4      5\\nHandreiking | Veilige Moskee\\nAanvullingen\\...   \n",
       "...                                                  ...   \n",
       "19097             6\\nT + 31 (0)\\n  \\n@amsterdam.nl \\n \\n   \n",
       "19098  Aantekeningen \\nZienswijzeverzoeken \\nBelanghe...   \n",
       "19099  Geheimhouding politiegegevens \\n(artikel 7, tw...   \n",
       "19100  55 \\nGemeente \\nE-mails over cijfermatige\\ndat...   \n",
       "19101  179 \\nGemeente \\nVoorstel onderzoek \\nwapencon...   \n",
       "\n",
       "                                                  text_y  \\\n",
       "0               \\n\\nHandreiking\\n\\nVeilige Moskee\\n\\n \\n   \n",
       "1      Handreiking | Veilige Moskee\\n\\nInhoudsopgave\\...   \n",
       "2      Handreiking | Veilige Moskee\\n\\n1. Inleiding\\n...   \n",
       "3      Handreiking | Veilige Moskee\\n\\nTips voor mosk...   \n",
       "4      Handreiking | Veilige Moskee\\n\\nAanvullingen\\n...   \n",
       "...                                                  ...   \n",
       "19097                  T + 32 N\\n\\n-®amsterdam.nl\\n\\n \\n   \n",
       "19098  Aantekeningen\\nZienswijzeverzoeken\\n\\n \\n\\n \\n...   \n",
       "19099   \\n\\nGeheimhouding politiegegevens\\n(artikel 7...   \n",
       "19100   \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n ...   \n",
       "19101   \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n ...   \n",
       "\n",
       "                                          text_y_cleaned  \\\n",
       "0                                 handreik veilig moskee   \n",
       "1      handreik veilig moskee inhoudsopgav inleid aar...   \n",
       "2      handreik veilig moskee inleid moskee gebedshui...   \n",
       "3      handreik veilig moskee tip moskee gemeent poli...   \n",
       "4      handreik veilig moskee aanvull handreik defini...   \n",
       "...                                                  ...   \n",
       "19097                                       amsterdam nl   \n",
       "19098  aanteken belanghebb partij document politie dr...   \n",
       "19099  geheimhoud politiegegeven artikel twed lid wpg...   \n",
       "19100  gemeent mail cijfermat gedeelt open art lid da...   \n",
       "19101  gemeent voorstel onderzoek gedeelt open art li...   \n",
       "\n",
       "                                                  header footer  ...  \\\n",
       "0                                                    NaN    NaN  ...   \n",
       "1                          Handreiking | Veilige Moskee      1   ...   \n",
       "2                          Handreiking | Veilige Moskee      3   ...   \n",
       "3                          Handreiking | Veilige Moskee      4   ...   \n",
       "4                          Handreiking | Veilige Moskee      5   ...   \n",
       "...                                                  ...    ...  ...   \n",
       "19097                  T + 31 (0)     @amsterdam.nl          6   ...   \n",
       "19098               Aantekeningen  Zienswijzeverzoeken      NaN  ...   \n",
       "19099  Geheimhouding politiegegevens  (artikel 7, twe...    NaN  ...   \n",
       "19100  55  Gemeente  E-mails over cijfermatige datage...    NaN  ...   \n",
       "19101  179  Gemeente  Voorstel onderzoek  wapencontro...    NaN  ...   \n",
       "\n",
       "      1_cos_char3 1_jac_char3   2_cos_3   2_jac_3  2_cos_char3  2_jac_char3  \\\n",
       "0        0.898450    0.625000  0.164153  0.013605     0.512104     0.082645   \n",
       "1        0.975678    0.880000  0.042796  0.022222     0.701130     0.497561   \n",
       "2        0.986773    0.920000  0.038490  0.019900     0.873152     0.602362   \n",
       "3        0.983317    0.857143  0.022635  0.009585     0.879288     0.628205   \n",
       "4        0.982468    0.960000  0.046524  0.017045     0.760221     0.547325   \n",
       "...           ...         ...       ...       ...          ...          ...   \n",
       "19097    0.659141    0.416667  0.000000  0.000000     0.059602     0.040000   \n",
       "19098    0.960295    1.000000  0.000000  0.000000     0.667565     0.420635   \n",
       "19099    0.000000    0.000000  0.000000  0.000000     0.000000     0.000000   \n",
       "19100    0.000000    0.000000  0.000000  0.000000     0.000000     0.000000   \n",
       "19101    0.000000    0.000000  0.000000  0.000000     0.000000     0.000000   \n",
       "\n",
       "        3_cos_3   3_jac_3  3_cos_char3  3_jac_char3  \n",
       "0      0.081111  0.006579     0.476742     0.032573  \n",
       "1      0.022283  0.011111     0.400137     0.187359  \n",
       "2      0.019631  0.009901     0.650754     0.256065  \n",
       "3      0.006080  0.003096     0.630186     0.325933  \n",
       "4      0.012189  0.005587     0.480749     0.231579  \n",
       "...         ...       ...          ...          ...  \n",
       "19097  0.000000  0.000000     0.004637     0.006079  \n",
       "19098  0.000000  0.000000     0.356729     0.146233  \n",
       "19099  0.000000  0.000000     0.000000     0.000000  \n",
       "19100  0.000000  0.000000     0.000000     0.000000  \n",
       "19101  0.000000  0.000000     0.000000     0.000000  \n",
       "\n",
       "[19102 rows x 89 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = c1_sims[~pd.isnull(c1_sims['text_y_cleaned'])]\n",
    "test_clean = c2_sims[~pd.isnull(c2_sims['text_y_cleaned'])]\n",
    "\n",
    "train = c1_sims\n",
    "test = c2_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "size    69.707824\n",
       "P        0.823313\n",
       "R        0.331486\n",
       "F1       0.314790\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['1_cos_-1','1_cos_1']\n",
    "# features = ['2_cos_-3','2_cos_-2','2_cos_-1','2_cos_1','2_cos_2','2_cos_3']\n",
    "# features = ['3_cos_-3','3_cos_-2','3_cos_-1','3_cos_1','3_cos_2','3_cos_3']\n",
    "# features = ['2_jac_-3','2_jac_-2','2_jac_-1','2_jac_1','2_jac_2','2_jac_3']\n",
    "# features = ['2_cos_char-3','2_cos_char-2','2_cos_char-1','2_cos_char1','2_cos_char2','2_cos_char3']\n",
    "features = ['2_jac_char-3','2_jac_char-2','2_jac_char-1','2_jac_char1','2_jac_char2','2_jac_char3']\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_clean[features], train_clean['label'])\n",
    "\n",
    "X_test = test_clean[features]\n",
    "y_test = test_clean['label']\n",
    "true = y_test\n",
    "preds = model.predict(X_test)\n",
    "vb_truth, vb_pred = change_format(y_test.values), change_format(model.predict(X_test))\n",
    "\n",
    "MeanBcubed(vb_truth, vb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dit', 'is'), ('is', 'een'), ('een', 'test')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tuples_nosentences('dit is een test', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_tuples_char' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25556\\2972934364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_tuples_char\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_y_cleaned'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_tuples_char' is not defined"
     ]
    }
   ],
   "source": [
    "get_tuples_char(train.iloc[5]['text_y_cleaned'], 3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0ef08d8ed6cc4ea55e1d44bd248b5018e6b6290053252328e46dd8d04768404"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('thesis8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
